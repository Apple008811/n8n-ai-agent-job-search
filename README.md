# Intelligent Job Collection AI Agent


## ğŸ¯ Project Objective

**Objective**: Automatically extract job listings from LinkedIn job alerts received via Gmail and synchronize them into a structured Notion database.

**Methods**:
- **Cursor as Pair Programmer**: Implement manual vibe coding functionality for rapid development and iteration
- **n8n Workflow Automation**: Integrate all components into a seamless pipeline, enabling twice-daily automated job collection

**Benefits**: Transform chaotic email notifications into a comprehensive positions database, allowing users to focus on the jobs themselves rather than manual data collection. This automation saves 10+ hours of searching, clicking, and organizing work, significantly improving job search efficiency.

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Job Collection System Architecture            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”„ Method 1: Gmail Email Parsing (For Closed Platforms)
codeâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gmail Alerts  â”‚â”€â”€â”€â–¶â”‚   n8n Workflow  â”‚â”€â”€â”€â–¶â”‚   Notion DB    
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ LinkedIn      â”‚    â”‚ â€¢ Gmail Nodes   â”‚    â”‚ â€¢ Job List      â”‚
â”‚ â€¢ Indeed        â”‚    â”‚ â€¢ Email Parser  â”‚    â”‚ â€¢ Deduplication â”‚
â”‚ â€¢ Glassdoor     â”‚    â”‚ â€¢ Notion Nodes  â”‚    â”‚ â€¢ Search        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸŒ Method 2: Direct Web Scraping (For Open Platforms)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Direct Sites  â”‚â”€â”€â”€â–¶â”‚   n8n Workflow  â”‚â”€â”€â”€â–¶â”‚   Notion DB     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Apple Jobs    â”‚    â”‚ â€¢ HTTP Request  â”‚    â”‚ â€¢ Job List      â”‚
â”‚ â€¢ Google Careersâ”‚    â”‚ â€¢ Universal     â”‚    â”‚ â€¢ Deduplication â”‚
â”‚ â€¢ Greenhouse    â”‚    â”‚   Parser        â”‚    â”‚ â€¢ Search        â”‚
â”‚ â€¢ Workday       â”‚    â”‚ â€¢ Notion Nodes  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   AI Services   â”‚
                       â”‚                 â”‚
                       â”‚ â€¢ LLM Analysis  â”‚
                       â”‚ â€¢ RAG Chat      â”‚
                       â”‚ â€¢ Resume Parser â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Progresses

**âœ… Phase 1, Implemented**:
- **ğŸ¤– Job Collection Agent**: Fully operational LinkedIn job extraction from Gmail
- **ğŸ“§ Gmail Integration**: Automated LinkedIn job alert processing
- **ğŸ“ Notion Integration**: Unified job database with intelligent deduplication
- **ğŸ”„ n8n Automation**: Reliable workflow orchestration and scheduling
- **ğŸŒ Universal Parser**: Supports Apple, Google, Microsoft, Amazon, Meta, Netflix, Stripe
- **ğŸ”§ Platform Parsers**: Greenhouse, Workday, Lever, BambooHR, SmartRecruiters
- **ğŸ“§ Email Parsers**: LinkedIn, Indeed, Glassdoor job alerts
- **Deduplication**: Intelligent conflict resolution with existing jobs

**ğŸ”„ Phase 2, In Development**:
- **ğŸ§  LLM Reasoning**: AI-powered content analysis and job matching 
- **ğŸ’¬ Chat Interface**: Interactive job search assistant with RAG capabilities
- **ğŸ“„ Resume Parser**: AI-powered resume customization and analysis


## ğŸ”§ Technical Stack

- **Workflow Engine**: n8n
- **Database**: Notion
- **AI Integration**: Cursor AI (Pro)
- **Email Processing**: Gmail API
- **Job Parsing**: Universal JavaScript parsers (Apple, Google, Microsoft, Amazon, Meta, Netflix, Stripe, Greenhouse, Workday, Lever, BambooHR, SmartRecruiters, LinkedIn, Indeed, Glassdoor)
- **Data Processing**: JavaScript/Node.js
- **API Service**: Flask (Python)
- **Containerization**: Docker & Docker Compose (local execution only)
- **Infrastructure**: Multi-container orchestration with shared networking


### Core Principles

- **Modular Design**: Each agent is independent and can be maintained separately
- **Unified Data Format**: All data sources output the same structure
- **Configuration-Driven**: Easy to add new data sources through configuration
- **Backward Compatible**: New features don't affect existing functionality

### n8n Code Node Limitations

**Sandbox Environment**: n8n Code nodes run in a sandboxed environment with the following restrictions:
- **No Global State**: Cannot access global variables or maintain state across executions
- **No Persistence**: Each execution is isolated and cannot remember previous data
- **Limited Scope**: Cannot access system resources, files, or external APIs directly
- **Cross-Execution Deduplication**: Cannot implement true global deduplication across multiple workflow runs

**Impact on Job Collection**: 
- Deduplication only works within a single workflow execution
- Each workflow run starts with a clean state
- For persistent deduplication, consider alternative tools like Airbyte or custom scripts



## ğŸ”§ Configuration

### Gmail Integration

#### Workflow Node Configuration

| Node | Purpose | Configuration | Key Details |
|------|---------|---------------|-------------|
| **Schedule Trigger (Morning)** | Daily morning execution | â€¢ Cron: "0 10 * * *" (10:00 AM)<br>â€¢ Timezone: Local<br>â€¢ Active: True | â€¢ Triggers Gmail collection<br>â€¢ Captures overnight job alerts<br>â€¢ First daily execution<br>â€¢ **Requires computer to be powered on** |
| **Schedule Trigger (Evening)** | Daily evening execution | â€¢ Cron: "0 20 * * *" (8:00 PM)<br>â€¢ Timezone: Local<br>â€¢ Active: True | â€¢ Triggers Gmail collection<br>â€¢ Captures afternoon job alerts<br>â€¢ Second daily execution<br>â€¢ **Requires computer to be powered on** |
| **Gmail (Get Many)** | Retrieve email list | â€¢ Resource: Message<br>â€¢ Operation: Get Many<br>â€¢ Limit: 20<br>â€¢ Search: "newer_than:1d"<br>â€¢ Sender: "jobalerts-noreply@linkedin.com" | â€¢ AND relationship for filters<br>â€¢ Daily latest emails only<br>â€¢ Strict LinkedIn filtering<br>â€¢ Output: Email metadata array |
| **Code (Time Converter)** | Convert timestamps | â€¢ Mode: Run Once for All Items<br>â€¢ Language: JavaScript<br>â€¢ Input: Email array with Unix timestamps | â€¢ **Critical for deduplication**: internalDate as unique identifier<br>â€¢ **Essential for testing**: Human-readable time format<br>â€¢ **Dual format**: Preserves original + adds readable format<br>â€¢ **Timezone handling**: Converts to America/New_York |
| **Loop** | Iterate through emails | â€¢ Input: Email array from Time Converter<br>â€¢ Mode: Run Once for Each Item<br>â€¢ Batch Size: 1 | â€¢ **Required for individual processing**: Gmail (Get) needs single email ID<br>â€¢ **Enables full content retrieval**: Each email processed separately<br>â€¢ **Prevents API overload**: Sequential processing vs batch |
| **Gmail (Get)** | Get full email content | â€¢ Resource: Message<br>â€¢ Operation: Get<br>â€¢ Message ID: From Loop<br>â€¢ Format: Full | â€¢ Retrieves complete HTML content<br>â€¢ Required for job parsing<br>â€¢ 1 API call per email<br>â€¢ **Important**: Does not preserve upstream fields like `readableDate` |
| **Code Parser** | Parse job information | â€¢ Language: JavaScript<br>â€¢ Input: Full email HTML<br>â€¢ Output: Structured job data | â€¢ Extracts job titles, companies, links<br>â€¢ Handles multiple jobs per email<br>â€¢ **Deduplication logic** |
| **Notion** | Store job data | â€¢ Database: Job Search Table<br>â€¢ Operation: Create<br>â€¢ Fields: Auto-mapped<br>â€¢ **Duplicate Check**: Job Title + Company | â€¢ Unified job storage<br>â€¢ Extensible table structure<br>â€¢ **Automatic deduplication** |

### Notion Integration

#### Database Schema

| Field | Type | Description | Auto/Manual |
|-------|------|-------------|-------------|
| Job Title | Title | Position name | Auto |
| Link | URL | Application link | Auto |
| Onsite/Remote/Hybrid | Select | Work type | Auto |
| Apply Date | Date | Application date | Manual |
| Status | Select | Application status | Manual |
| Re-apply | Checkbox | Re-application flag | Manual |

#### Critical Setup Steps

1. **Create Notion Integration**
   - Go to https://www.notion.so/my-integrations
   - Create new integration: "n8n Job Search AI Agent"
   - Select workspace: "Yixuan Jing's Notion HQ" (not Private)
   - Copy Internal Integration Secret

2. **Database Creation**
   - Create database in Notion with 6 fields as shown above
   - Convert simple table to database (not just a table)
   - Get database ID from URL: `https://notion.so/database-id`

3. **Access Permissions**
   - In integration settings, go to "Access" tab
   - Add database to "Manually selected" permissions
   - Ensure integration has access to the database

### Greenhouse Job Parser

#### Supported Job Board Types

The parser automatically detects and handles different job board formats:

- **Standard Greenhouse**: `boards.greenhouse.io/company`
- **Custom Greenhouse**: Company-specific implementations
- **LinkedIn Jobs**: For deduplication purposes
- **Generic Fallback**: For unknown formats

#### Database Schema Mapping

| Greenhouse Field | Notion Field | Type | Description |
|------------------|--------------|------|-------------|
| `title` | Job Title | Title | Job position title |
| `url` | Link | URL | Complete application URL |
| `location` | Onsite/Remote/Hybrid | Text | Work location |
| `company` | - | - | Company name (used for deduplication) |
| `department` | - | - | Department (used for filtering) |
| `type` | - | - | Employment type (used for filtering) |



## ğŸ“Š Performance & Monitoring

### API Rate Limits

#### Gmail API Quota Details

| Quota Type | Limit | Our Usage | Status |
|------------|-------|-----------|---------|
| **Daily Requests** | 1,000,000 requests/day | ~50 requests/day | âœ… 0.005% of limit |
| **Rate Limit** | 100 requests/second | ~1 request/second | âœ… Well within limit |
| **Monthly Usage** | ~30,000,000 requests | ~2,500 requests | âœ… 0.008% of limit |
| **Annual Usage** | ~365,000,000 requests | ~30,000 requests | âœ… 0.008% of limit |

#### Current Workflow Usage

| Operation | Frequency | Daily Calls | Monthly Calls |
|-----------|-----------|-------------|---------------|
| Schedule Triggers | 2 times/day (10:00 AM, 8:00 PM) | 2 triggers | 60 triggers |
| Gmail (Get Many) | 2 times/day | 2 calls | 60 calls |
| Loop (20 emails) | 2 times/day | 40 calls | 1,200 calls |
| Gmail (Get) | 2 times/day | 40 calls | 1,200 calls |
| **Total** | - | **82 calls** | **2,460 calls** |

### Deduplication Strategy

| Method | Criteria | Implementation | Benefits |
|--------|----------|----------------|----------|
| **Primary Key** | Job Title + Company | Notion database unique constraint | â€¢ Prevents exact duplicates<br>â€¢ Handles LinkedIn re-sends<br>â€¢ Database-level protection |
| **Content Hash** | Email content hash | Code Parser JavaScript logic | â€¢ Detects similar job postings<br>â€¢ Handles minor variations<br>â€¢ Application-level filtering |
| **Time Window** | 24-hour overlap | Gmail search "newer_than:1d" | â€¢ Natural deduplication<br>â€¢ Prevents old job re-processing<br>â€¢ Efficient API usage |

### Personal Usage Time Investment

For individual users, the time investment is minimal and practical:

- **New Parser Development**: 1-2 hours
  - Quick analysis of job board structure
  - Copy and modify existing parser template
  - Test and validate functionality
  - Deploy to n8n workflow

- **Regular Maintenance**: 30 minutes per month
  - Check if all parsers are working correctly
  - Verify data quality in Notion database
  - Clean up any duplicate entries
  - Update documentation if needed

- **Issue Resolution**: On-demand basis
  - Fix parsing issues when they occur
  - Update selectors when websites change
  - Troubleshoot n8n workflow problems
  - No complex monitoring or alerting needed

### Security Considerations

- OAuth2 authentication for Gmail
- Secure credential storage
- Rate limiting to prevent abuse
- Data privacy compliance



## ğŸ“ Project Structure

### ğŸ”§ Core n8n Workflow Files

| ğŸ“„ File | ğŸ¯ Purpose | ğŸ”— Usage in n8n |
|---------|------------|-----------------|
| `job_parser.js` | Main job parsing logic | **Code Parser node** - extracts job details from LinkedIn emails |
| `time_converter.js` | Timestamp conversion utility | **Code (Time Converter) node** - converts Unix timestamps to readable format |
| `debug_gmail_get.js` | Gmail debugging tool | **Debug node** - inspects Gmail (Get) node output structure |
| `test_current_state.js` | State testing utility | **Test node** - validates current workflow state |
| `gmail_parser.js` | Legacy email parser | **Backup parser** - early version of email parsing logic |

### ğŸ¯ Job Parser Files

| ğŸ“„ File | ğŸ¯ Purpose | ğŸ”— Usage in n8n |
|---------|------------|-----------------|
| `universal_company_parser.js` | **Universal parser** | **Code node** - automatically detects and parses any company/platform |
| `apple_parser.js` | Apple job parser | **Code node** - extracts jobs from Apple career pages |
| `greenhouse_optimized.js` | Greenhouse job parser | **Code Parser node** - extracts jobs from Greenhouse job boards |
| `stripe_parser.js` | Stripe job parser | **Code node** - extracts jobs from Stripe custom job board |
| `notion_job_mapper.js` | Notion integration | **Code node** - maps job data to Notion database schema |
| `test_apple_parser.js` | Apple test suite | **Test node** - validates Apple parser functionality |
| `test_apple_integration.js` | Integration tests | **Test node** - end-to-end testing for Apple parser |
| `apple_job_filter_example.js` | Filter examples | **Code node** - job filtering and search examples |

### ğŸ API Service Files

| ğŸ“„ File | ğŸ¯ Purpose | ğŸ“ Description |
|---------|------------|----------------|
| `app.py` | Flask API service | Python web service for content analysis and file processing |
| `llm_rag_service.py` | LLM RAG service | AI-powered chat and analysis service |
| `requirements.txt` | Python dependencies | Flask, PyPDF2, BeautifulSoup4, pandas, matplotlib, plotly |

### ğŸ³ Deployment & Infrastructure

| ğŸ“„ File | ğŸ¯ Purpose | ğŸ“ Description |
|---------|------------|----------------|
| `Dockerfile` | Container configuration | Builds Python API service container with Flask |
| `docker-compose.yml` | Service orchestration | Multi-service setup: n8n, API, and LLM RAG services |
| `workflows/` | n8n workflow templates | Sample workflows for different use cases |
| `workflows/apple_job_collector.json` | Apple job collector | **n8n workflow** - automated Apple job collection |

### âš™ï¸ Configuration & Documentation

| ğŸ“„ File | ğŸ¯ Purpose | ğŸ“ Description |
|---------|------------|----------------|
| `config_backup.md` | Configuration backup | Contains all API credentials and settings (âš ï¸ **NOT in Git**) |
| `README.md` | Project documentation | Complete setup and usage guide |
| `LICENSE` | MIT License | Open source license |


## ğŸ›ï¸ Build up in Cursor

### Prompts

#### 1) Connect Cursor (AI Agent) to this repo
- "Open the repository in Cursor and act as my Pair Programmer. Goal: build an LLM-powered job collection agent using n8n, Gmail API, and Notion. Keep code in English, minimal UI, and document steps in README."
- "Scan the codebase and summarize the workflow from Gmail â†’ Parser â†’ Notion. Identify integration points for a chat/RAG layer."
- "Generate a minimal Flask endpoint for `/chat` that accepts a question and returns a placeholder response. Add unit tests if trivial."

#### 2) n8n workflow bootstrapping
- "Create an n8n workflow: Webhook (POST /chat) â†’ HTTP Request to my Flask `/chat` â†’ Respond to Webhook. Return JSON { response, relevant_jobs, timestamp }."
- "Create a second webhook (POST /add-job) that forwards job JSON to my `/add_job` endpoint."
- "Export the workflow as JSON and save it under `workflows/llm_rag_chat.json`."

#### 3) Gmail API integration prompts
- "Guide me to create Gmail OAuth2 credentials. Output the exact steps and where to paste Client ID/Secret in n8n."
- "In n8n, configure Gmail (Get Many) to filter: sender `jobalerts-noreply@linkedin.com`, search `newer_than:1d`, limit 20."
- "Add a Code node using `time_converter.js`, then Loop â†’ Gmail (Get) full message â†’ Code `job_parser.js` â†’ Notion. Ensure `emailTime` survives."

#### 4) Notion integration prompts
- "Walk me through creating a Notion integration and database. Fields: Job Title (Title), Link (URL), Onsite/Remote/Hybrid (Select/Rich Text)."
- "Map n8n Notion node properties exactly: Title = `={{ $json.jobTitle }}`, Link = `={{ $json.jobLink }}`, Work Type = `={{ $json.workType }}`."
- "Test with 3 sample items and verify entries appear in Notion without property errors."

#### 5) LLM + RAG chat layer (Phase 2)
- "Add `OPENAI_API_KEY` to env. Start the `llm_rag_service.py` on port 5001."
- "POST /add_job with a sample job. Then POST /chat with: 'Find remote data roles in SF Bay Area'. Confirm recommendations include the added job if relevant."
- "Serve `chat_interface.html` locally and test a full chat round-trip via n8n webhook."







## ğŸ¤– AI Agents

### Phase 1: Job Collection Automation âœ… **IMPLEMENTED**

**Purpose**: Automatically collect job postings from multiple sources and store them in a unified Notion database.

**Implemented Features**:
- âœ… **Gmail Integration**: Successfully configured and tested
- âœ… **LinkedIn Job Alerts**: Automated extraction from Gmail (87 job entries processed)
- âœ… **Notion Integration**: Database connection and property mapping completed
- âœ… **End-to-End Workflow**: Complete automation pipeline operational
- âœ… **Greenhouse Parser**: Universal parser with smart deduplication
- âœ… **Custom Job Boards**: Stripe and other company-specific parsers
- âœ… **Deduplication**: Intelligent conflict resolution with existing jobs

**Data Sources**:
- **Gmail (LinkedIn Job Alerts)**: Primary source for job notifications âœ…
- **Greenhouse**: Universal job board parser âœ…
- **Custom Job Boards**: Stripe and other company-specific pages âœ…
- **Manual Input**: User-added job opportunities âœ…

### Phase 2: LLM Reasoning & Intelligence ğŸ”„ **IN DEVELOPMENT**

**Purpose**: Add AI-powered reasoning, analysis, and intelligent job matching capabilities.

**Planned Features**:
- ğŸ”„ **LLM Reasoning**: AI analysis of job requirements and candidate matching
- ğŸ”„ **Intelligent Job Recommendations**: AI-powered job suggestions based on skills
- ğŸ”„ **Resume Customization**: AI analysis and resume tailoring for specific jobs
- ğŸ”„ **Chat Interface**: Interactive job search assistant with RAG capabilities
- ğŸ”„ **Skills Matching**: Automatic skills extraction and job matching

**Current Status**: LLM reasoning layer is under development but not yet implemented.

### Phase 3: Advanced Features ğŸ“‹ **PLANNED**

**Purpose**: Advanced career development and research automation.

**Planned Capabilities**:
- ğŸ“‹ **Research Agent**: Academic and professional research automation
- ğŸ“‹ **Company Intelligence**: Auto-fetch company information and insights
- ğŸ“‹ **Application Tracking**: Track application status and follow-up reminders
- ğŸ“‹ **Salary Analysis**: Market data and compensation insights

### Cancelled Features âŒ **NOT IMPLEMENTING**

**Events Integration**: Originally planned to integrate tech events and conferences, but due to API limitations and membership requirements, this feature has been cancelled for now.



## ğŸš€ Setup Instructions

### ğŸ“‹ Prerequisites

- âœ… Docker and Docker Compose
- âœ… Gmail API credentials
- âœ… Notion API access
- âœ… Cursor Pro subscription

### ğŸ³ Quick Start with Docker

1. **Clone the repository**
   ```bash
   git clone https://github.com/Apple008811/n8n-ai-agent-job-search.git
   cd n8n-ai-agent-job-search
   ```

2. **Start services with Docker Compose**
   ```bash
   docker-compose up -d
   ```

3. **Access n8n interface**
   - ğŸŒ Open http://localhost:5678
   - âš™ï¸ Complete n8n setup wizard

4. **Access API service**
   - ğŸ”Œ API available at http://localhost:5002
   - â¤ï¸ Health check: http://localhost:5002/health

> âš ï¸ **Important**: Docker containers run locally and require your computer to be powered on. The automated job collection (scheduled at 10:00 AM and 8:00 PM daily) will only execute when your computer is running and the containers are active. If your computer is shut down or in sleep mode, the scheduled tasks will not trigger.

### ğŸ”§ Manual Setup (Alternative)

1. **Install n8n locally**
   ```bash
   npm install n8n -g
   n8n start
   ```

2. **Set up Python API service**
   ```bash
   pip install -r requirements.txt
   python app.py
   ```

3. **Configure API credentials**
   - ğŸ“§ Gmail OAuth2 credentials
   - ğŸ“ Notion integration token
   - ğŸ’¾ Update `config_backup.md` with your settings

### âš™ï¸ n8n Workflow Configuration

1. **Import workflow templates**
   - ğŸ“„ Use `workflows/` directory as reference
   - ğŸ†• Create new workflow for Job Search Agent

2. **Configure Code nodes**
   - ğŸ“‹ Copy content from respective `.js` files
   - ğŸ”„ Set node modes (Run Once for All Items vs Each Item)

3. **Set up API connections**
   - ğŸ“§ Gmail API (OAuth2)
   - ğŸ“ Notion API (Token)
   - ğŸŒ HTTP Request nodes for external APIs

## ğŸ“– Usage Guide

### Daily Job Search

1. **Automated Collection**: Gmail automatically collects LinkedIn job alerts
2. **Smart Parsing**: System parses job information using AI
3. **Data Storage**: Jobs stored in Notion database with deduplication
4. **User Review**: User reviews and applies to relevant positions

### Greenhouse Job Parser

#### Basic Usage

```javascript
const { parseGreenhouseJobs, searchGreenhouseJobs } = require('./greenhouse_optimized.js');

// Parse jobs from Greenhouse HTML
const jobs = parseGreenhouseJobs(html, 'Company Name');

// Search for specific jobs
const engineerJobs = searchGreenhouseJobs(jobs, { title: 'Engineer' });
const remoteJobs = searchGreenhouseJobs(jobs, { location: 'Remote' });
```

#### Notion Integration

```javascript
const { parseAndMapToNotion } = require('./notion_job_mapper.js');

// Parse and map to Notion format (with deduplication)
const notionPages = parseAndMapToNotion(html, 'Company Name', existingLinkedInJobs);
```

### Resume Customization

1. **Upload**: Upload resume and job description
2. **AI Analysis**: AI analyzes requirements and matches skills
3. **Generate**: Generate customized resume
4. **Export**: Export optimized version

## ğŸ“‹ Standard Operating Procedure

### Overview

This SOP outlines the complete process for developing new job collection agents, from initial prompts to production deployment.

### Phase 1: Planning & Requirements

#### 1.1 Initial Prompt
Start with a clear, specific prompt that defines the scope and requirements:

```
"Create a [JOB_BOARD_TYPE] job parser that:
- Extracts job titles, locations, departments, and application URLs
- Integrates with existing Notion Job List database
- Prevents duplicates with existing LinkedIn jobs
- Supports advanced filtering and search
- Follows the established code patterns in this repository"
```

#### 1.2 Requirements Analysis
- **Data Source**: Identify the job board URL and structure
- **Data Fields**: Map required fields to Notion schema
- **Integration Points**: Define how it connects to existing systems
- **Deduplication**: Specify conflict resolution with existing data
- **Performance**: Set parsing speed and accuracy targets

#### 1.3 Create TODO List
Use the todo_write tool to track progress:

```javascript
todo_write({
  merge: false,
  todos: [
    { id: 'analyze_source', content: 'Analyze job board HTML structure and data format', status: 'in_progress' },
    { id: 'create_parser', content: 'Create specialized parser for the job board', status: 'pending' },
    { id: 'notion_mapping', content: 'Map parser output to Notion database schema', status: 'pending' },
    { id: 'deduplication', content: 'Implement duplicate detection against existing jobs', status: 'pending' },
    { id: 'testing', content: 'Create comprehensive test suite', status: 'pending' },
    { id: 'n8n_integration', content: 'Create n8n workflow for automation', status: 'pending' },
    { id: 'documentation', content: 'Update README with usage instructions', status: 'pending' }
  ]
});
```

### Phase 2: Code Development

#### 2.1 Parser Development
Create the core parsing logic:

```javascript
// File: [job_board]_parser.js
// 1. Analyze HTML structure
// 2. Implement multiple parsing methods (JSON, HTML, fallback)
// 3. Extract job data with error handling
// 4. Add comprehensive logging
// 5. Follow English-only code and comments rule
```

#### 2.2 Notion Integration
Create mapping functions:

```javascript
// File: notion_[job_board]_mapper.js
// 1. Map parser output to Notion schema
// 2. Implement deduplication logic
// 3. Handle data validation and cleaning
// 4. Add export functionality for manual import
```

#### 2.3 Testing Suite
Create comprehensive tests:

```javascript
// File: test_[job_board]_parser.js
// 1. Unit tests for parsing functions
// 2. Integration tests with Notion mapping
// 3. Deduplication tests with existing data
// 4. Error handling and edge case tests
// 5. Performance benchmarks
```

### Phase 3: n8n Configuration

#### 3.1 Workflow Design
Create the n8n workflow structure:

```json
{
  "name": "[Job Board] Job Collector",
  "nodes": [
    {
      "name": "Cron Trigger",
      "type": "n8n-nodes-base.cron",
      "parameters": {
        "rule": {
          "interval": [{"field": "cronExpression", "expression": "0 9 * * *"}]
        }
      }
    },
    {
      "name": "HTTP Request",
      "type": "n8n-nodes-base.httpRequest",
      "parameters": {
        "url": "https://[job-board-url]",
        "method": "GET"
      }
    },
    {
      "name": "Code - Parse Jobs",
      "type": "n8n-nodes-base.code",
      "parameters": {
        "jsCode": "const { parseJobs } = require('./[parser-file]');\nconst jobs = parseJobs($input.first().json.html, 'Company Name');\nreturn jobs.map(job => ({ json: job }));"
      }
    },
    {
      "name": "Notion - Create Page",
      "type": "n8n-nodes-base.notion",
      "parameters": {
        "operation": "create",
        "databaseId": "your-database-id",
        "properties": {
          "Job Title": "={{ $json.title }}",
          "Link": "={{ $json.url }}",
          "Onsite/Remote/Hybrid": "={{ $json.location }}"
        }
      }
    }
  ]
}
```

### Phase 4: Testing & Validation

#### 4.1 Unit Testing
Run individual component tests:

```bash
# Test parser functionality
node test_[job_board]_parser.js

# Test Notion integration
node test_notion_[job_board]_mapper.js

# Test deduplication
node test_deduplication.js
```

#### 4.2 Integration Testing
Test complete workflow:

```bash
# Test n8n workflow
n8n execute --workflow workflows/[job_board]_collector.json

# Test with real data
n8n execute --workflow workflows/[job_board]_test.json
```

### Phase 5: Documentation & Deployment

#### 5.1 Update README
Add comprehensive documentation with:
- Overview and features
- Installation instructions
- Usage examples
- Configuration options
- Testing instructions
- Troubleshooting guide

#### 5.2 Create Examples
Provide practical examples:
- Complete working examples
- Real-world usage scenarios
- Best practices demonstration

### Phase 6: Maintenance & Monitoring

#### 6.1 Monitoring Setup
- Set up logging for parsing success/failure rates
- Monitor Notion API usage and limits
- Track duplicate detection accuracy
- Monitor n8n workflow execution

#### 6.2 Regular Maintenance
- Weekly: Review parsing accuracy
- Monthly: Update parser for site changes
- Quarterly: Performance optimization
- As needed: Bug fixes and improvements

### Best Practices

#### Code Quality
- **English Only**: All code, comments, and documentation in English
- **Error Handling**: Comprehensive error handling and logging
- **Testing**: Unit tests for all functions
- **Documentation**: Clear, comprehensive documentation
- **Performance**: Optimize for speed and memory usage

#### Integration
- **Modularity**: Keep components independent and reusable
- **Configuration**: Use configuration files for easy updates
- **Validation**: Validate all data before processing
- **Deduplication**: Always check for duplicates
- **Security**: Follow security best practices


## ğŸ“‹ Development Roadmap

### Phase 2: LLM Reasoning & Intelligence ğŸ”„ **CURRENT FOCUS**
- [ ] **LLM Reasoning Engine** - Implement AI-powered job analysis and candidate matching
- [ ] **Chat Interface** - Interactive job search assistant with RAG capabilities
- [ ] **Resume Parser** - AI-powered resume customization and analysis
- [ ] **Skills Matching** - Automatic skills extraction and job matching
- [ ] **Job Recommendations** - AI-powered job suggestions based on profile

### Phase 3: Advanced Features ğŸ“‹ **PLANNED**
- [ ] **Research Agent** - Academic and professional research automation
- [ ] **Company Intelligence** - Auto-fetch company information from Glassdoor/Crunchbase
- [ ] **Application Tracking** - Track application status and follow-up reminders
- [ ] **Salary Analysis** - Market data and compensation insights
- [ ] **Career Progression** - Long-term career development analytics

### Phase 4: Platform Expansion ğŸš€ **FUTURE**
- [ ] **Multi-platform Support** - Add Indeed, AngelList, GitHub Jobs, Stack Overflow Jobs
- [ ] **Advanced Filtering** - Filter jobs by keywords, location, salary range, company size
- [ ] **Machine Learning** - Learn from user preferences and application history
- [ ] **Automated Applications** - One-click application for compatible job boards
- [ ] **Interview Integration** - Calendar integration for interview management

### Improvements & Maintenance ğŸ”§ **ONGOING**
- [ ] **Work Type Parsing** - Improve detection logic (currently extracting "Unknown")
- [ ] **Repository Rename** - Consider renaming from `job-search` to `job-collection-platform`
- [ ] **Performance Optimization** - Enhance parsing speed and accuracy
- [ ] **Error Handling** - Improve robustness and error recovery

### Cancelled Features âŒ **NOT IMPLEMENTING**
- **Events Integration** - Originally planned to integrate tech events and conferences, but due to API limitations and membership requirements, this feature has been cancelled for now

## ğŸ“‹ Table of Contents

- [ğŸ›ï¸ Quick Start](#ï¸-quick-start)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ¤– AI Agents](#-ai-agents)
- [ğŸ”§ Technical Stack](#-technical-stack)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸš€ Setup Instructions](#-setup-instructions)
- [ğŸ“– Usage Guide](#-usage-guide)
- [ğŸ“‹ Standard Operating Procedure](#-standard-operating-procedure)
- [ğŸ”§ Configuration](#-configuration)
- [ğŸ“Š Performance & Monitoring](#-performance--monitoring)
- [ğŸ“‹ Development Roadmap](#-development-roadmap)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)



## ğŸ¤ Contributing

This project is designed for personal use but can be extended for broader applications.

## ğŸ“„ License

Private project for personal career development.