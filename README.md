# Job Search AI Agent

An intelligent job collection and automation platform that combines LLM reasoning with n8n workflow automation for seamless job discovery and data management.

## ✨ Highlights

This project uniquely combines **LLM reasoning capabilities** with **n8n workflow automation** to create a powerful job collection and intelligence platform. The LLM provides intelligent content parsing and job matching, while n8n ensures reliable automation and seamless data flow between Gmail, Notion, and external APIs. This synergistic approach delivers superior automation with AI-enhanced accuracy and scalable architecture for future enhancements.

## Project Overview

This project consists of three main AI agents designed to streamline job search and career development:

1. **Job Search Agent** - Automated job discovery and collection ✅ **COMPLETED**
2. **Resume Parser Agent** - Resume customization based on job descriptions
3. **Research Agent** - Academic and professional research automation

## Current Status

### ✅ Job Search Agent - COMPLETED
- **Gmail Integration**: Successfully configured and tested
- **Email Processing**: 87 job entries extracted from LinkedIn alerts
- **Notion Integration**: Database connection and property mapping completed
- **Data Flow**: End-to-end workflow operational
- **Next Steps**: Configure dual schedule triggers (10:00 AM and 8:00 PM)

### 🔄 In Progress
- **Work Type Parsing**: Currently extracting "Unknown" - needs improvement
- **Schedule Triggers**: Need to configure morning and evening execution

### 📋 Pending
- **Resume Parser Agent**: Development pending
- **Research Agent**: Development pending

## Architecture Design

### Core Principles
- **Modular Design**: Each agent is independent and can be maintained separately
- **Unified Data Format**: All data sources output the same structure
- **Configuration-Driven**: Easy to add new data sources through configuration
- **Backward Compatible**: New features don't affect existing functionality

## Job Search Agent

### Purpose
Automatically collect job postings from multiple sources and store them in a unified Notion database.

### Data Sources
- **Gmail (LinkedIn Job Alerts)**: Primary source for job notifications
- **Indeed**: Web scraping for job postings
- **Glassdoor**: Company and salary information
- **AngelList**: Startup job opportunities
- **Company Career Pages**: Direct company job postings
- **Manual Input**: User-added job opportunities

### Workflow Architecture

```
Schedule Trigger → Gmail (Get Many) → Time Converter → Loop → Gmail (Get Full Message) → Add ReadableDate Node → Job Parser → Notion
Schedule Trigger (Daily) → Indeed Scraper → Code Parser → Notion
Manual Input → Code Parser → Notion
```

**Data Flow for LinkedIn Job Alerts:**
1. **Gmail (Get Many)** → Outputs email metadata with `internalDate` (Unix timestamp)
2. **Time Converter** → Adds `readableDate` and `emailTime` fields to each email
3. **Loop** → Iterates through Time Converter output (each item has time fields)
4. **Gmail (Get Full Message)** → Retrieves complete email content using email ID from Loop
5. **Add ReadableDate Node** → Ensures `emailTime` field is preserved (email receipt time in Pacific timezone)
6. **Job Parser** → Receives full email data + time fields, extracts job details
7. **Notion** → Creates database entries with job data + email timestamps

**Key Point**: `emailTime` is generated by the Time Converter node, not by Gmail Get Messages. The Loop node enables individual email processing, and the Add ReadableDate Node ensures time fields are preserved through the Gmail (Get Full Message) node. Use `{{ $json.emailTime }}` in Notion for the email receipt time.

### Gmail Integration Details

#### Important Gmail Node Behavior

**Gmail (Get Full Message) Node Field Preservation Issue:**

The Gmail (Get Full Message) node has a critical limitation: **it does not preserve upstream fields from previous nodes**. When this node retrieves complete email content from Gmail API, it outputs only the raw Gmail data and discards any fields added by upstream nodes (like `readableDate` and `emailTime` from Time Converter).

**Available Options in Gmail (Get Full Message) Node:**
- **Attachment Prefix**: Used for attachment filename prefix
- **Download Attachments**: Controls whether to download email attachments
- **None of these options preserve upstream fields**

**Solution:**
The Job Parser includes fallback logic to regenerate time fields from `internalDate` when upstream time fields are missing, ensuring `readableDate` is always available for Notion mapping.

#### Workflow Node Configuration

| Node | Purpose | Configuration | Key Details |
|------|---------|---------------|-------------|
| **Schedule Trigger (Morning)** | Daily morning execution | • Cron: "0 10 * * *" (10:00 AM)<br>• Timezone: Local<br>• Active: True | • Triggers Gmail collection<br>• Captures overnight job alerts<br>• First daily execution |
| **Schedule Trigger (Evening)** | Daily evening execution | • Cron: "0 20 * * *" (8:00 PM)<br>• Timezone: Local<br>• Active: True | • Triggers Gmail collection<br>• Captures afternoon job alerts<br>• Second daily execution |
| **Gmail (Get Many)** | Retrieve email list | • Resource: Message<br>• Operation: Get Many<br>• Limit: 20<br>• Search: "newer_than:1d"<br>• Sender: "jobalerts-noreply@linkedin.com" | • AND relationship for filters<br>• Daily latest emails only<br>• Strict LinkedIn filtering<br>• Output: Email metadata array |
| **Code (Time Converter)** | Convert timestamps | • Mode: Run Once for All Items<br>• Language: JavaScript<br>• Input: Email array with Unix timestamps | • **Critical for deduplication**: internalDate as unique identifier<br>• **Essential for testing**: Human-readable time format<br>• **Dual format**: Preserves original + adds readable format<br>• **Timezone handling**: Converts to America/New_York |
| **Loop** | Iterate through emails | • Input: Email array from Time Converter<br>• Mode: Run Once for Each Item<br>• Batch Size: 1 | • **Required for individual processing**: Gmail (Get) needs single email ID<br>• **Enables full content retrieval**: Each email processed separately<br>• **Prevents API overload**: Sequential processing vs batch |
| **Gmail (Get)** | Get full email content | • Resource: Message<br>• Operation: Get<br>• Message ID: From Loop<br>• Format: Full | • Retrieves complete HTML content<br>• Required for job parsing<br>• 1 API call per email<br>• **Important**: Does not preserve upstream fields like `readableDate` |
| **Code Parser** | Parse job information | • Language: JavaScript<br>• Input: Full email HTML<br>• Output: Structured job data | • Extracts job titles, companies, links<br>• Handles multiple jobs per email<br>• **Deduplication logic** |
| **Notion** | Store job data | • Database: Job Search Table<br>• Operation: Create<br>• Fields: Auto-mapped<br>• **Duplicate Check**: Job Title + Company | • Unified job storage<br>• Extensible table structure<br>• **Automatic deduplication** |

**Output Structure**:
```json
{
  "id": "19915f09235dcae4",
  "threadId": "1991439703dc91dc",
  "snippet": "View jobs in California",
  "subject": "30+ new jobs for strategic finance",
  "from": "LinkedIn Job Alerts <jobalerts-noreply@linkedin.com>",
  "to": "yixuanjing116@gmail.com",
  "date": "2025-01-02T07:17:00Z",
  "payload": {
    "mimeType": "multipart/alternative",
    "sizeEstimate": 164519,
    "historyId": 7644778,
    "internalDate": 1756860281000
  },
  "labels": ["INBOX", "CATEGORY_UPDATES", "UNREAD"]
}
```

**Limitations**:
- Only provides email preview (snippet), not full content
- Cannot extract specific job details from email body
- Limited to basic metadata and email structure information

#### Gmail (Get) Node
**Purpose**: Retrieve complete email content including HTML body
**Input**: Email ID from Gmail (Get Many)
**Output**: Full email content with HTML body

**Why Both Nodes Are Needed**:

**Gmail API Design**: Gmail API is divided into two operations:
- `messages.list` (Get Many): Retrieve email list
- `messages.get` (Get): Retrieve single email content

**Efficiency Considerations**:
- Retrieving 20 email list: 1 API call
- Retrieving 20 complete email contents: 20 API calls

**Quota Management**:
- Avoid unnecessary API calls
- Filter first, then retrieve detailed content

**Current Architecture is Optimal**:
- Gmail (Get Many): Fast retrieval of email list
- Gmail (Get): Complete content extraction for job parsing

### Data Processing Pipeline

#### 1. Email Collection
- **Gmail Trigger**: Real-time email monitoring
- **Gmail (Get Many)**: Batch email retrieval
- **Loop**: Iterate through each email
- **Gmail (Get)**: Extract full content

#### 2. Job Parsing
- **Code Node**: Parse HTML content
- **Extract**: Job titles, companies, locations, salaries, links
- **Transform**: Standardize data format
- **Deduplicate**: Remove duplicate entries

#### 3. Data Storage
- **Notion Integration**: Store in unified database
- **Fields**: Job Title, Company, Location, Salary, Link, Source, Date, Status

### Notion Database Schema

| Field | Type | Description | Auto/Manual |
|-------|------|-------------|-------------|
| Job Title | Title | Position name | Auto |
| Link | URL | Application link | Auto |
| Onsite/Remote/Hybrid | Select | Work type | Auto |
| Apply Date | Date | Application date | Manual |
| Status | Select | Application status | Manual |
| Re-apply | Checkbox | Re-application flag | Manual |

### Notion Integration Configuration

#### Critical Setup Steps

1. **Create Notion Integration**
   - Go to https://www.notion.so/my-integrations
   - Create new integration: "n8n Job Search AI Agent"
   - Select workspace: "Yixuan Jing's Notion HQ" (not Private)
   - Copy Internal Integration Secret

2. **Database Creation**
   - Create database in Notion with 6 fields as shown above
   - Convert simple table to database (not just a table)
   - Get database ID from URL: `https://notion.so/database-id`

3. **Access Permissions**
   - In integration settings, go to "Access" tab
   - Add database to "Manually selected" permissions
   - Ensure integration has access to the database

#### n8n Notion Node Configuration

| Setting | Value | Notes |
|---------|-------|-------|
| **Credential** | Notion API (Token) | Use Internal Integration Secret |
| **Resource** | Database Page | For creating new entries |
| **Operation** | Create | Create new database entries |
| **Database** | By ID | Use database ID from URL |
| **Title** | `={{ $json.jobTitle }}` | Dynamic job title |
| **Properties** | See mapping below | Field-by-field configuration |

#### Property Mapping Configuration

**Important**: Only map fields that are automatically captured by the system. Manual maintenance fields should NOT be included in n8n mapping.

| Notion Field | Data Source | n8n Mapping | n8n Value | Notes |
|--------------|-------------|-------------|-----------|-------|
| **Job Title** | Auto-captured | ✅ Required | `={{ $json.jobTitle }}` | System parsed from emails |
| **Link** | Auto-captured | ✅ Required | `={{ $json.jobLink }}` | System extracted LinkedIn URLs |
| **Onsite/Remote/Hybrid** | Auto-captured | ✅ Required | `={{ $json.workType }}` | System parsed work type (Rich Text) |
| **Apply Date** | Manual maintenance | ❌ Not needed | - | User manually fills |
| **Status** | Manual maintenance | ❌ Not needed | - | User manually selects |
| **Re-apply** | Manual maintenance | ❌ Not needed | - | User manually checks |

**Field Name Requirements**:
- Must match Notion database field names **exactly** (case-sensitive)
- Include spaces, slashes, and special characters
- Examples: `Job Title` (not `JobTitle`), `Onsite/Remote/Hybrid` (not `onsite/remote/hybrid`)

**Onsite/Remote/Hybrid Field Type**:
- **Recommended**: Rich Text type for maximum flexibility
- **Alternative**: Select type with options: `Remote`, `Hybrid`, `Onsite`, `Unknown`
- Rich Text allows any work type value without predefined constraints

**Column Order Flexibility**:
- You can freely rearrange column order in Notion database
- n8n maps by **field name**, not by position
- Only field names must match exactly (case-sensitive)

#### Common Issues and Solutions

| Issue | Error Message | Solution |
|-------|---------------|----------|
| **Wrong Workspace** | Integration not found | Select correct workspace in integration settings |
| **Page vs Database** | "is a page, not a database" | Convert table to database, get database ID |
| **Missing Permissions** | "Error fetching options" | Add database to integration access |
| **Property Mismatch** | "should be defined, instead was undefined" | Match exact property names from Notion |
| **Duplicate Title** | Title conflicts | Use Title field for page title, separate property for job title |

#### Database ID Extraction

**From Database URL:**
```
https://notion.so/2644ae56fb5a80229babdd248426236c?v=2654ae56fb5a8058bf55000cc593ea4c
```

**Database ID:**
```
2644ae56fb5a80229babdd248426236c
```

#### Testing and Validation

1. **Connection Test**: Green checkmark next to database name
2. **Property Detection**: Dropdown shows all database fields
3. **Data Flow Test**: 87 job entries successfully processed
4. **Error Resolution**: All property mapping errors resolved

## Resume Parser Agent

### Purpose
Customize resumes based on specific job descriptions using AI analysis.

### Features
- PDF/Word resume upload
- Job description analysis
- AI-powered customization suggestions
- Optimized resume generation

## Research Agent

### Purpose
Automate academic and professional research workflows.

### Capabilities
- Paper collection and analysis
- Data processing and simulation
- Results analysis and policy recommendations
- Multi-source data integration

## Technical Stack

- **Workflow Engine**: n8n
- **Database**: Notion
- **AI Integration**: Cursor AI (Pro)
- **Email Processing**: Gmail API
- **Web Scraping**: HTTP Request nodes
- **Data Processing**: JavaScript/Node.js
- **API Service**: Flask (Python)
- **Containerization**: Docker & Docker Compose

## 📁 Project File Structure

### 🔧 Core n8n Workflow Files

| 📄 File | 🎯 Purpose | 🔗 Usage in n8n |
|---------|------------|-----------------|
| `job_parser.js` | Main job parsing logic | **Code Parser node** - extracts job details from LinkedIn emails |
| `time_converter.js` | Timestamp conversion utility | **Code (Time Converter) node** - converts Unix timestamps to readable format |
| `debug_gmail_get.js` | Gmail debugging tool | **Debug node** - inspects Gmail (Get) node output structure |
| `test_current_state.js` | State testing utility | **Test node** - validates current workflow state |
| `gmail_parser.js` | Legacy email parser | **Backup parser** - early version of email parsing logic |

### 🐍 API Service Files

| 📄 File | 🎯 Purpose | 📝 Description |
|---------|------------|----------------|
| `app.py` | Flask API service | Python web service for content analysis and file processing |
| `requirements.txt` | Python dependencies | Flask, PyPDF2, BeautifulSoup4, pandas, matplotlib, plotly |

### 🐳 Deployment & Infrastructure

| 📄 File | 🎯 Purpose | 📝 Description |
|---------|------------|----------------|
| `Dockerfile` | Container configuration | Builds Python API service container |
| `docker-compose.yml` | Service orchestration | Orchestrates n8n and API service containers |
| `workflows/simple_analysis.json` | n8n workflow template | Sample workflow for content analysis |

### ⚙️ Configuration & Documentation

| 📄 File | 🎯 Purpose | 📝 Description |
|---------|------------|----------------|
| `config_backup.md` | Configuration backup | Contains all API credentials and settings (⚠️ NOT in Git) |
| `README.md` | Project documentation | Complete setup and usage guide |
| `LICENSE` | MIT License | Open source license |

### 🚀 Quick Usage Guide

#### 📋 Code Nodes Configuration
1. **Time Converter**: Copy `time_converter.js` content → Paste in Code node
2. **Job Parser**: Copy `job_parser.js` content → Paste in Code Parser node  
3. **Debug Tool**: Copy `debug_gmail_get.js` content → Paste in Debug node
4. **Test Tool**: Copy `test_current_state.js` content → Paste in Test node

#### 🔌 API Integration
1. **Flask Service**: Deploy `app.py` for file processing and analysis
2. **Docker Deployment**: Use `docker-compose.yml` for full stack deployment

## 🚀 Setup Instructions

### 📋 Prerequisites
- ✅ Docker and Docker Compose
- ✅ Gmail API credentials
- ✅ Notion API access
- ✅ Cursor Pro subscription

### 🐳 Quick Start with Docker

1. **Clone the repository**
   ```bash
   git clone https://github.com/Apple008811/n8n-ai-agent-job-search.git
   cd n8n-ai-agent-job-search
   ```

2. **Start services with Docker Compose**
   ```bash
   docker-compose up -d
   ```

3. **Access n8n interface**
   - 🌐 Open http://localhost:5678
   - ⚙️ Complete n8n setup wizard

4. **Access API service**
   - 🔌 API available at http://localhost:5002
   - ❤️ Health check: http://localhost:5002/health

### 🔧 Manual Setup (Alternative)

1. **Install n8n locally**
   ```bash
   npm install n8n -g
   n8n start
   ```

2. **Set up Python API service**
   ```bash
   pip install -r requirements.txt
   python app.py
   ```

3. **Configure API credentials**
   - 📧 Gmail OAuth2 credentials
   - 📝 Notion integration token
   - 💾 Update `config_backup.md` with your settings

### ⚙️ n8n Workflow Configuration

1. **Import workflow templates**
   - 📄 Use `workflows/simple_analysis.json` as reference
   - 🆕 Create new workflow for Job Search Agent

2. **Configure Code nodes**
   - 📋 Copy content from respective `.js` files
   - 🔄 Set node modes (Run Once for All Items vs Each Item)

3. **Set up API connections**
   - 📧 Gmail API (OAuth2)
   - 📝 Notion API (Token)
   - 🌐 HTTP Request nodes for external APIs

## Usage

### Daily Job Search
1. Gmail automatically collects LinkedIn job alerts
2. System parses job information
3. Data stored in Notion database
4. User reviews and applies

### Resume Customization
1. Upload resume and job description
2. AI analyzes requirements
3. Generate customized resume
4. Export optimized version

## API Rate Limits

### Gmail API Quota Details

| Quota Type | Limit | Our Usage | Status |
|------------|-------|-----------|---------|
| **Daily Requests** | 1,000,000 requests/day | ~50 requests/day | ✅ 0.005% of limit |
| **Rate Limit** | 100 requests/second | ~1 request/second | ✅ Well within limit |
| **Monthly Usage** | ~30,000,000 requests | ~2,500 requests | ✅ 0.008% of limit |
| **Annual Usage** | ~365,000,000 requests | ~30,000 requests | ✅ 0.008% of limit |

### Current Workflow Usage

| Operation | Frequency | Daily Calls | Monthly Calls |
|-----------|-----------|-------------|---------------|
| Schedule Triggers | 2 times/day (10:00 AM, 8:00 PM) | 2 triggers | 60 triggers |
| Gmail (Get Many) | 2 times/day | 2 calls | 60 calls |
| Loop (20 emails) | 2 times/day | 40 calls | 1,200 calls |
| Gmail (Get) | 2 times/day | 40 calls | 1,200 calls |
| **Total** | - | **82 calls** | **2,460 calls** |

### Deduplication Strategy

| Method | Criteria | Implementation | Benefits |
|--------|----------|----------------|----------|
| **Primary Key** | Job Title + Company | Notion database unique constraint | • Prevents exact duplicates<br>• Handles LinkedIn re-sends<br>• Database-level protection |
| **Content Hash** | Email content hash | Code Parser JavaScript logic | • Detects similar job postings<br>• Handles minor variations<br>• Application-level filtering |
| **Time Window** | 24-hour overlap | Gmail search "newer_than:1d" | • Natural deduplication<br>• Prevents old job re-processing<br>• Efficient API usage |

## Configuration Backup

### Critical Configuration Files
- **`config_backup.md`**: Complete configuration backup with all credentials and settings (⚠️ **NOT in Git**)
- **`gmail_parser.js`**: Email parsing logic
- **`time_converter.js`**: Timestamp conversion logic
- **`job_parser.js`**: Job data extraction logic

### Backup Best Practices
1. **Always save Client Secret immediately after generation**
2. **Document all configuration changes in `config_backup.md`**
3. **Keep credential information secure and up-to-date**
4. **⚠️ NEVER commit credentials to Git or public repositories**
5. **Use `.gitignore` to exclude sensitive files**

### Development Best Practices
1. **Never delete working nodes without testing alternatives first**
2. **Add new nodes for testing, keep existing ones as backup**
3. **Compare outputs before making changes**
4. **Test thoroughly before replacing existing functionality**
5. **Maintain parallel workflows during development**

### Quota Monitoring

- ✅ **Far below limit**: Usage is less than 0.1% of quota
- ✅ **Safety margin**: Sufficient buffer space for expansion
- ✅ **Scalable**: Can support additional data sources and features
- ✅ **Cost-effective**: No additional charges for current usage

## Security Considerations

- OAuth2 authentication for Gmail
- Secure credential storage
- Rate limiting to prevent abuse
- Data privacy compliance

## 📋 TODO List

### 🚀 High Priority
- [ ] **Rename GitHub repository** from `job-search` to `job-collection-platform` to better reflect project purpose
- [ ] **Improve work type parsing** - Currently extracting "Unknown" for most jobs, need better detection logic
- [ ] **Add job filtering system** - Filter jobs by keywords, location, salary range, company size
- [ ] **Multi-platform job collection** - Add support for Indeed, AngelList, GitHub Jobs, Stack Overflow Jobs

### 🔄 Medium Priority  
- [ ] **Enhanced job matching** - AI-powered job recommendations based on skills and preferences
- [ ] **Company research integration** - Auto-fetch company information from Glassdoor/Crunchbase
- [ ] **Application tracking** - Track application status and follow-up reminders
- [ ] **Resume customization** - AI-powered resume tailoring for specific job applications

### 📈 Future Enhancements
- [ ] **Machine learning job matching** - Learn from user preferences and application history
- [ ] **Automated application submission** - One-click application for compatible job boards
- [ ] **Interview scheduling integration** - Calendar integration for interview management
- [ ] **Salary negotiation insights** - Market data and negotiation tips
- [ ] **Career progression tracking** - Long-term career development analytics


## Contributing

This project is designed for personal use but can be extended for broader applications.

## License

Private project for personal career development.
